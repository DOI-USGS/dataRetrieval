%\VignetteIndexEntry{Introduction to the dataRetrieval package}
%\VignetteEngine{knitr::knitr}
%\VignetteDepends{}
%\VignetteSuggests{xtable, testthat}
%\VignetteImports{XML, RCurl, reshape2,lubridate,plyr,utils,stats}
%\VignettePackage{dataRetrieval}

\documentclass[a4paper,11pt]{article}

\usepackage{amsmath}
\usepackage{times}
\usepackage{hyperref}
\usepackage[numbers, round]{natbib}
\usepackage[american]{babel}
\usepackage{authblk}
\usepackage{subfig}
\usepackage{placeins}
\usepackage{footnote}
\usepackage{tabularx}
\usepackage{threeparttable}
\usepackage{parskip}

\usepackage{csquotes}
\usepackage{setspace}

% \doublespacing

\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\usepackage{graphicx}


\usepackage{mathptmx}% Times Roman font
\usepackage[scaled=.90]{helvet}% Helvetica, served as a model for arial

% \usepackage{indentfirst}
% \setlength\parindent{20pt}
\setlength{\parskip}{0pt}

\usepackage{courier}

\usepackage{titlesec}
\usepackage{titletoc}

\titleformat{\section}
  {\normalfont\sffamily\bfseries\LARGE}
  {\thesection}{0.5em}{}
\titleformat{\subsection}
  {\normalfont\sffamily\bfseries\Large}
  {\thesubsection}{0.5em}{}
\titleformat{\subsubsection}
  {\normalfont\sffamily\large}
  {\thesubsubsection}{0.5em}{}
  
\titlecontents{section}
[2em]                 % adjust left margin
{\sffamily}             % font formatting
{\contentslabel{2.3em}} % section label and offset
{\hspace*{-2.3em}}
{\titlerule*[0.25pc]{.}\contentspage}
  
\titlecontents{subsection}
[4.6em]                 % adjust left margin
{\sffamily}             % font formatting
{\contentslabel{2.3em}} % section label and offset
{\hspace*{-2.3em}}
{\titlerule*[0.25pc]{.}\contentspage}
  
\titlecontents{subsubsection}
[6.9em]                 % adjust left margin
{\sffamily}             % font formatting
{\contentslabel{2.3em}} % section label and offset
{\hspace*{-2.3em}}
{\titlerule*[0.25pc]{.}\contentspage}

\titlecontents{table}
[0em]                 % adjust left margin
{\sffamily}             % font formatting
{Table\hspace*{2em} \contentslabel {2em}} % section label and offset
{\hspace*{4em}}
{\titlerule*[0.25pc]{.}\contentspage}

\titlecontents{figure}
[0em]                 % adjust left margin
{\sffamily}             % font formatting
{Figure\hspace*{2em} \contentslabel {2em}} % section label and offset
{\hspace*{4em}}
{\titlerule*[0.25pc]{.}\contentspage}

%Italisize and change font of urls:
\urlstyle{sf}
\renewcommand\UrlFont\itshape

\usepackage{caption}
\captionsetup{
  font={sf},
  labelfont={bf,sf},
  labelsep=period,
  justification=justified,
  singlelinecheck=false
}



\textwidth=6.2in
\textheight=8.5in
\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in


%------------------------------------------------------------
% newcommand
%------------------------------------------------------------
\newcommand{\scscst}{\scriptscriptstyle}
\newcommand{\scst}{\scriptstyle}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{\textit{#1}}
\newcommand{\Rpackage}[1]{\textit{#1}}
\newcommand{\Rexpression}[1]{\texttt{#1}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}

\begin{document}

<<openLibrary, echo=FALSE>>=
library(xtable)
options(continue=" ")
options(width=60)
library(knitr)

@

\renewenvironment{knitrout}{\begin{singlespace}}{\end{singlespace}}
\renewcommand*\listfigurename{Figures}

\renewcommand*\listtablename{Tables}


%------------------------------------------------------------
\title{The dataRetrieval R package}
%------------------------------------------------------------
\author[1]{Laura A. De Cicco}
\author[1]{Robert M. Hirsch}
\affil[1]{United States Geological Survey}


<<include=TRUE ,echo=FALSE,eval=TRUE>>=
opts_chunk$set(highlight=TRUE, tidy=TRUE, keep.space=TRUE, keep.blank.space=FALSE, keep.comment=TRUE, tidy=FALSE,comment="")
knit_hooks$set(inline = function(x) {
   if (is.numeric(x)) round(x, 3)})
knit_hooks$set(crop = hook_pdfcrop)

bold.colHeaders <- function(x) {
  x <- gsub("\\^(\\d)","$\\^\\1$",x)
  x <- gsub("\\%","\\\\%",x)
  x <- gsub("\\_"," ",x)
  returnX <- paste("\\multicolumn{1}{c}{\\textbf{\\textsf{", x, "}}}", sep = "")
}
addSpace <- function(x) ifelse(x != "1", "[5pt]","")
library(dataRetrieval)
@

\noindent{\huge\textsf{\textbf{The dataRetrieval R package}}}

\noindent\textsf{By Laura A. De Cicco and Robert M. Hirsch}

\noindent\textsf{\today}

% \maketitle
% 
% \newpage 

\tableofcontents
\listoffigures
\listoftables

\newpage

%------------------------------------------------------------
\section{Introduction to dataRetrieval}
%------------------------------------------------------------ 
The dataRetrieval package was created to simplify the process of loading hydrologic data into the R environment. It is designed to retrieve the major data types of U.S. Geological Survey (USGS) hydrologic data that are available on the Web, as well as data from the Water Quality Portal (WQP), which currently houses water quality data from the Environmental Protection Agency (EPA), U.S. Department of Agriculture (USDA), and USGS. Direct USGS data is obtained from a service called the National Water Information System (NWIS). A lot of useful information about NWIS can be obtained here:

\url{http://help.waterdata.usgs.gov/}

For information on getting started in R and installing the package, see (\ref{sec:appendix1}): Getting Started. Any use of trade, firm, or product names is for descriptive purposes only and does not imply endorsement by the U.S. Government.

A quick workflow for USGS dataRetrieval functions:

<<workflow, echo=TRUE,eval=FALSE>>=
library(dataRetrieval)
# Choptank River near Greensboro, MD
siteNumber <- "01491000" 
ChoptankInfo <- readNWISsite(siteNumber)
parameterCd <- "00060"

#Raw daily data:
rawDailyData <- readNWISdv(siteNumber,parameterCd,
                      "1980-01-01","2010-01-01")

# Sample data Nitrate:
parameterCd <- "00618"
qwData <- readNWISqw(siteNumber,parameterCd,
                      "1980-01-01","2010-01-01")

pCode <- readNWISpCode(parameterCd)

@

USGS data are made available through the National Water Information System (NWIS).

Table \ref{tab:func} describes the functions available in the dataRetrieval package.

\begin{table}[!ht]
\begin{minipage}{\linewidth}
{\footnotesize
\caption{dataRetrieval functions} 
\label{tab:func}
\begin{tabular}{lll}
  \hline
\multicolumn{1}{c}{\textbf{\textsf{Function Name}}} &
\multicolumn{1}{c}{\textbf{\textsf{Arguments}}}  &
\multicolumn{1}{c}{\textbf{\textsf{Description}}} \\  [0pt]
  \hline
  \texttt{readNWISdata} &  \texttt{...} & NWIS data using user-specified queries\\
   & service & \\
  [5pt]\texttt{readNWISdv} & siteNumber & NWIS daily data\\
  & parameterCd & \\
  & startDate & \\
  & endDate & \\
  & statCd & \\
  [5pt]\texttt{readNWISqw} & siteNumber & NWIS water quality data\\
    & parameterCd & \\
  & startDate & \\
  & endDate & \\
  & expanded & \\
  [5pt]\texttt{readNWISuv} & siteNumber & NWIS water quality data\\
  & parameterCd & \\
  & startDate & \\
  & endDate & \\
  [5pt]\texttt{readNWISrating} & siteNumber & NWIS rating table for active streamgage \\
  & type & \\
  [5pt]\texttt{readNWISmeas} & siteNumber & NWIS surface-water measurements \\
  & startDate & \\
  & endDate & \\
  [5pt]\texttt{readNWISpeak} & siteNumber & NWIS peak flow data \\
  & startDate & \\
  & endDate & \\
  [5pt]\texttt{readNWISgwl} & siteNumber & NWIS groundwater level measurements \\
  & startDate & \\
  & endDate & \\  
  [5pt]\texttt{readNWISpCode} & parameterCd & NWIS parameter code information\\
  [5pt]\texttt{readNWISsite} & siteNumber & NWIS site information \\
  [5pt]\texttt{whatNWISsites} & \texttt{...} & NWIS site search using user-specified queries \\
  [5pt]\texttt{whatNWISdata} & siteNumber & NWIS data availability, including period of record and count \\ 
   & service & \\
   [5pt]\texttt{readWQPdata} & \texttt{...} & WQP data using user-specified queries \\
   [5pt]\texttt{readWQPqw} & siteNumber & WQP data \\
     & parameterCd (or characteristic name) & \\
  & startDate & \\
  & endDate & \\
  [5pt]\texttt{whatWQPsites} & \texttt{...} & WQP site search using user-specified queries \\  
   \hline
\end{tabular}
}
\end{minipage}
\end{table}

\clearpage

%------------------------------------------------------------
\section{USGS Web Retrievals}
\label{sec:genRetrievals}
%------------------------------------------------------------ 
In this section, examples of Web retrievals document how to get raw data. This data includes site information (\ref{sec:usgsSite}), measured parameter information (\ref{sec:usgsParams}), historical daily values(\ref{sec:usgsDaily}), unit values (which include real-time data but can also include other sensor data stored at regular time intervals) (\ref{sec:usgsRT}), water quality data (\ref{sec:usgsWQP}), groundwater level data (\ref{sec:gwl}), peak flow data (\ref{sec:peak}), rating curve data (\ref{sec:rating}, and surface-water measurement data (\ref{sec:meas}). Section \ref{sec:metadata} shows instructions for getting metadata that is attached to each returned data frame.

The USGS organizes hydrologic data in a standard structure.  Streamgages are located throughout the United States, and each streamgage has a unique ID (referred in this document and throughout the dataRetrieval package as \enquote{siteNumber}).  Often (but not always), these ID's are 8 digits for surface-water sites and 15 digits for groundwater sites.  The first step to finding data is discovering this siteNumber. There are many ways to do this, one is the National Water Information System: Mapper \url{http://maps.waterdata.usgs.gov/mapper/index.html}.

Once the siteNumber is known, the next required input for USGS data retrievals is the \enquote{parameter code}.  This is a 5-digit code that specifies the measured parameter being requested.  For example, parameter code 00631 represents \enquote{Nitrate plus nitrite, water, filtered, milligrams per liter as nitrogen}, with units of \enquote{mg/l as N}. 

A useful place to discover USGS codes information, along with other NWIS information is:

\url{http://help.waterdata.usgs.gov/codes-and-parameters}

Not every station will measure all parameters. A short list of commonly measured parameters is shown in Table \ref{tab:params}.


<<tableParameterCodes, echo=FALSE,results='asis'>>=
pCode <- c('00060', '00065', '00010','00045','00400')
shortName <- c("Discharge [ft$^3$/s]","Gage height [ft]","Temperature [C]", "Precipitation [in]", "pH")

data.df <- data.frame(pCode, shortName, stringsAsFactors=FALSE)

print(xtable(data.df,
       label="tab:params",
       caption="Common USGS Parameter Codes"),
       caption.placement="top",
       size = "\\footnotesize",
       latex.environment=NULL,
       sanitize.text.function = function(x) {x},
       sanitize.colnames.function =  bold.colHeaders,
       sanitize.rownames.function = addSpace
      )

@

Two output columns that may not be obvious are \enquote{srsname} and \enquote{casrn}. Srsname stands for \enquote{Substance Registry Services}. More information on the srs name can be found here:

\url{http://ofmpub.epa.gov/sor_internet/registry/substreg/home/overview/home.do}

Casrn stands for \enquote{Chemical Abstracts Service (CAS) Registry Number}. More information on CAS can be found here:

\url{http://www.cas.org/content/chemical-substances/faqs}

For unit values data (sensor data measured at regular time intervals such as 15 minutes or hourly), knowing the parameter code and siteNumber is enough to make a request for data.  For most variables that are measured on a continuous basis, the USGS also stores the historical data as daily values.  These daily values are statistical summaries of the continuous data, e.g. maximum, minimum, mean, or median. The different statistics are specified by a 5-digit statistics code.  A complete list of statistic codes can be found here:

\url{http://help.waterdata.usgs.gov/code/stat_cd_nm_query?stat_nm_cd=%25&fmt=html&inline=true}

Some common codes are shown in Table \ref{tab:stat}.

<<tableStatCodes, echo=FALSE,results='asis'>>=
StatCode <- c('00001', '00002', '00003','00008')
shortName <- c("Maximum","Minimum","Mean", "Median")

data.df <- data.frame(StatCode, shortName, stringsAsFactors=FALSE)

print(xtable(data.df,label="tab:stat",
           caption="Commonly used USGS Stat Codes"),
       caption.placement="top",
       size = "\\footnotesize",
       latex.environment=NULL,
       sanitize.colnames.function = bold.colHeaders,
       sanitize.rownames.function = addSpace
      )

@

Examples for using these siteNumbers, parameter codes, and stat codes will be presented in subsequent sections.

\FloatBarrier

%------------------------------------------------------------
\subsection{Site Information}
\label{sec:usgsSite}
%------------------------------------------------------------

%------------------------------------------------------------
\subsubsection{readNWISsite}
\label{sec:usgsSiteFileData}
%------------------------------------------------------------
Use the \texttt{readNWISsite} function to obtain all of the information available for a particular USGS site (or sites) such as full station name, drainage area, latitude, and longitude. \texttt{readNWISsite} can also access information about multiple sites with a vector input.


<<getSite, echo=TRUE, eval=FALSE>>=
siteNumbers <- c("01491000","01645000") 
siteINFO <- readNWISsite(siteNumbers)
@

Site information is obtained from:
\url{http://waterservices.usgs.gov/rest/Site-Test-Tool.html}

Information on the returned data can be found with the \texttt{comment} function as described in section \ref{sec:metadata}.

<<siteNames3, echo=TRUE, eval=FALSE>>=
comment(siteINFO)
@



\FloatBarrier

%------------------------------------------------------------
\subsubsection{whatNWISdata}
\label{sec:usgsDataAvailability}
%------------------------------------------------------------
To discover what data is available for a particular USGS site, including measured parameters, period of record, and number of samples (count), use the \texttt{whatNWISdata} function. It is possible to limit the retrieval information to a subset of services. The possible choices for services are: \texttt{"}dv\texttt{"} (daily values), \texttt{"}uv\texttt{"}, \texttt{"}rt\texttt{"}, or \texttt{"}iv\texttt{"} (unit values), \texttt{"}qw\texttt{"} (water-quality), \texttt{"}sv\texttt{"} (sites visits), \texttt{"}pk\texttt{"} (peak measurements), \texttt{"}gw\texttt{"} (groundwater levels), \texttt{"}ad\texttt{"} (sites included in USGS Annual Water Data Reports External Link), \texttt{"}aw\texttt{"} (sites monitored by the USGS Active Groundwater Level Network External Link), and \texttt{"}id\texttt{"} (historical instantaneous values).

In the following example, we limit the retrieved data to only daily data. The default for \texttt{"}service\texttt{"} is \enquote{all}, which returns all of the available data for that site. Likewise, there are arguments for parameter code (\texttt{parameterCd}) and statistic code (\texttt{statCd}) to filter the results. The default for both is to return all possible values (\enquote{all}). The returned \texttt{"}count\_nu\texttt{"} for \texttt{"}uv\texttt{"} data is the count of days with returned data, not the actual count of returned values.


<<getSiteExtended, echo=TRUE, eval=FALSE>>=
# Continuing from the previous example:
# This pulls out just the daily, mean data:

dailyDataAvailable <- whatNWISdata(siteNumbers,
                    service="dv", statCd="00003")


@

<<tablegda, echo=FALSE,eval=FALSE>>=
tableData <- with(dailyDataAvailable, 
      data.frame( 
      siteNumber= site_no,
      srsname=srsname, 
      startDate=as.character(begin_date), 
      endDate=as.character(end_date), 
      count=as.character(count_nu),
      units=parameter_units,
#       statCd = stat_cd,
      stringsAsFactors=FALSE)
      )

tableData$units[which(tableData$units == "ft3/s")] <- "ft$^3$/s"
tableData$units[which(tableData$units == "uS/cm @25C")] <- "$\\mu$S/cm @25C"


print(xtable(tableData,label="tab:gda",
    caption="Reformatted version of output from \\texttt{whatNWISdata} function for the Choptank River near Greensboro, MD, and from Seneca Creek at Dawsonville, MD from the daily values service [Some columns deleted for space considerations]"),
       caption.placement="top",
       size = "\\footnotesize",
       latex.environment=NULL,
       sanitize.text.function = function(x) {x},
       sanitize.colnames.function =  bold.colHeaders,
       sanitize.rownames.function = addSpace
      )

@

\begin{table}[ht]
\caption{Reformatted version of output from \texttt{whatNWISdata} function for the Choptank River near Greensboro, MD, and from Seneca Creek at Dawsonville, MD from the daily values service [Some columns deleted for space considerations]} 
\label{tab:gda}
{\footnotesize
\begin{tabular}{rllllll}
  \hline
 & \multicolumn{1}{c}{\textbf{\textsf{siteNumber}}} & \multicolumn{1}{c}{\textbf{\textsf{srsname}}} & \multicolumn{1}{c}{\textbf{\textsf{startDate}}} & \multicolumn{1}{c}{\textbf{\textsf{endDate}}} & \multicolumn{1}{c}{\textbf{\textsf{count}}} & \multicolumn{1}{c}{\textbf{\textsf{units}}} \\ 
  \hline
 & 01491000 & Temperature, water & 2010-10-01 & 2012-05-09 & 529 & deg C \\ 
  [5pt] & 01645000 & Stream flow, mean. daily & 1930-09-26 & 2015-02-19 & 30828 & ft$^3$/s \\ 
  [5pt] & 01491000 & Stream flow, mean. daily & 1948-01-01 & 2015-02-19 & 24522 & ft$^3$/s \\ 
  [5pt] & 01491000 & Specific conductance & 2010-10-01 & 2012-05-09 & 527 & $\mu$S/cm @25C \\ 
  [5pt] & 01491000 & Suspended sediment concentration (SSC) & 1980-10-01 & 1991-09-30 & 3651 & mg/l \\ 
  [5pt] & 01491000 & Suspended sediment discharge & 1980-10-01 & 1991-09-30 & 3652 & tons/day \\ 
   \hline
\end{tabular}
}
\end{table}

See Section \ref{app:createWordTable} for instructions on converting an R data frame to a table in Microsoft\textregistered\ software Excel or Word to display a data availability table similar to Table \ref{tab:gda}. Excel, Microsoft, PowerPoint, Windows, and Word are registered trademarks of Microsoft Corporation in the United States and other countries.

\FloatBarrier

%------------------------------------------------------------
\subsection{Parameter Information}
\label{sec:usgsParams}
%------------------------------------------------------------
To obtain all of the available information concerning a measured parameter (or multiple parameters), use the \texttt{readNWISpCode} function:

<<label=getPCodeInfo, echo=TRUE, eval=FALSE>>=
# Using defaults:
parameterCd <- "00618" 
parameterINFO <- readNWISpCode(parameterCd)
@

More information on parameter codes can obtained from:

\url{http://help.waterdata.usgs.gov/codes-and-parameters/parameters}

\FloatBarrier

%------------------------------------------------------------
\subsection{Daily Data}
\label{sec:usgsDaily}
%------------------------------------------------------------
To obtain daily records of USGS data, use the \texttt{readNWISdv} function. The arguments for this function are siteNumber, parameterCd, startDate, endDate, and statCd (defaults to \texttt{"}00003\texttt{"}).  If you want to use the default values, you do not need to list them in the function call. Daily data is pulled from \url{http://waterservices.usgs.gov/rest/DV-Test-Tool.html}.

The dates (start and end) must be in the format \texttt{"}YYYY-MM-DD\texttt{"} (note: the user must include the quotes).  Setting the start date to \texttt{"}\texttt{"} (no space) will prompt the program to ask for the earliest date, and setting the end date to \texttt{"}\texttt{"} (no space) will prompt for the latest available date.

<<label=getNWISDaily, echo=TRUE, eval=FALSE>>=

# Choptank River near Greensboro, MD:
siteNumber <- "01491000"
parameterCd <- "00060"  # Discharge
startDate <- "2009-10-01"  
endDate <- "2012-09-30" 

discharge <- readNWISdv(siteNumber, 
                    parameterCd, startDate, endDate)
@

The column \texttt{"}datetime\texttt{"} in the returned data frame is automatically imported as a variable of class \texttt{"}Date\texttt{"} in R. Each requested parameter has a value and remark code column.  The names of these columns depend on the requested parameter and stat code combinations. USGS daily value qualification codes are often \texttt{"}A\texttt{"} (approved for publication) or \texttt{"}P\texttt{"} (provisional data subject to revision). A more complete list of daily value qualification codes can be found here:

\url{http://help.waterdata.usgs.gov/codes-and-parameters/daily-value-qualification-code-dv_rmk_cd}

Another example would be a request for mean and maximum daily temperature and discharge in early 2012:

<<label=getNWIStemperature, echo=TRUE, eval=FALSE>>=
siteNumber <- "01491000"
parameterCd <- c("00010","00060")  # Temperature and discharge
statCd <- c("00001","00003")  # Mean and maximum
startDate <- "2012-01-01"
endDate <- "2012-05-01"

temperatureAndFlow <- readNWISdv(siteNumber, parameterCd, 
        startDate, endDate, statCd=statCd)

@

<<label=getNWIStemperature2, echo=FALSE, eval=TRUE>>=
filePath <- system.file("extdata", package="dataRetrieval")
fileName <- "temperatureAndFlow.RData"
fullPath <- file.path(filePath, fileName)
load(fullPath)

@

The column names can be shortened and simplified using the \texttt{renameNWISColumns} function.  This is not necessary, but may streamline subsequent data analysis and presentation. Site information, daily statistic information, and measured parameter information is attached to the data frame as attributes. This is discused further in section \ref{sec:metadata}.


<<label=renameColumns, echo=TRUE>>=
names(temperatureAndFlow)

temperatureAndFlow <- renameNWISColumns(temperatureAndFlow)
names(temperatureAndFlow)

@

<<label=attr1, echo=TRUE>>=
#Information about the data frame attributes:
names(attributes(temperatureAndFlow))

statInfo <- attr(temperatureAndFlow, "statisticInfo")
variableInfo <- attr(temperatureAndFlow, "variableInfo")
siteInfo <- attr(temperatureAndFlow, "siteInfo")

@



An example of plotting the above data (Figure \ref{fig:getNWIStemperaturePlot}):

<<getNWIStemperaturePlot, echo=TRUE, fig.cap="Temperature and discharge plot of Choptank River in 2012.",out.width='1\\linewidth',out.height='1\\linewidth',fig.show='hold'>>=
variableInfo <- attr(temperatureAndFlow, "variableInfo")
siteInfo <- attr(temperatureAndFlow, "siteInfo")

par(mar=c(5,5,5,5)) #sets the size of the plot window

plot(temperatureAndFlow$Date, temperatureAndFlow$Wtemp_Max,
  ylab=variableInfo$parameter_desc[1],xlab="" )
par(new=TRUE)
plot(temperatureAndFlow$Date, temperatureAndFlow$Flow,
  col="red",type="l",xaxt="n",yaxt="n",xlab="",ylab="",axes=FALSE
  )
axis(4,col="red",col.axis="red")
mtext(variableInfo$parameter_desc[2],side=4,line=3,col="red")
title(paste(siteInfo$station_nm,"2012"))
legend("topleft", variableInfo$param_units, 
       col=c("black","red"),lty=c(NA,1),pch=c(1,NA))
@


There are occasions where NWIS values are not reported as numbers, instead there might be text describing a certain event such as \enquote{Ice.}  Any value that cannot be converted to a number will be reported as NA in this package (not including remark code columns).

\FloatBarrier

%------------------------------------------------------------
\subsection{Unit Data}
\label{sec:usgsRT}
%------------------------------------------------------------
Any data collected at regular time intervals (such as 15-minute or hourly) are known as \enquote{unit values.} Many of these are delivered on a real time basis and very recent data (even less than an hour old in many cases) are available through the function \texttt{readNWISuv}.  Some of these unit values are available for many years, and some are only available for a recent time period such as 120 days.  Here is an example of a retrieval of such data.  

<<label=readNWISuv, eval=FALSE>>=

parameterCd <- "00060"  # Discharge
startDate <- "2012-05-12" 
endDate <- "2012-05-13" 
dischargeUnit <- readNWISuv(siteNumber, parameterCd, 
        startDate, endDate)
dischargeUnit <- renameNWISColumns(dischargeUnit)
@

The retrieval produces a data frame that contains 96 rows (one for every 15 minute period in the day).  They include all data collected from the startDate through the endDate (starting and ending with midnight locally-collected time). The dateTime column is converted to \enquote{UTC} (Coordinated Universal Time), so midnight EST will be 5 hours earlier in the dateTime column (the previous day, at 7pm).

To override the UTC timezone, specify a valid timezone in the tz argument. Default is \texttt{""}, which will keep the dateTime column in UTC. Other valid timezones are:

\begin{verbatim}
America/New_York
America/Chicago
America/Denver
America/Los_Angeles
America/Anchorage
America/Honolulu
America/Jamaica
America/Managua
America/Phoenix
America/Metlakatla
\end{verbatim}

Data are retrieved from \url{http://waterservices.usgs.gov/rest/IV-Test-Tool.html}. There are occasions where NWIS values are not reported as numbers, instead a common example is \enquote{Ice.}  Any value that cannot be converted to a number will be reported as NA in this package. Site information and measured parameter information is attached to the data frame as attributes. This is discused further in section \ref{sec:metadata}.

\newpage


\FloatBarrier

%------------------------------------------------------------
\subsection{Water Quality Data}
\label{sec:usgsWQP}
%------------------------------------------------------------
To get USGS water quality data from water samples collected at the streamgage or other monitoring site (as distinct from unit values collected through some type of automatic monitor) we can use the function \texttt{readNWISqw}, with the input arguments: siteNumber, parameterCd, startDate, and endDate. Additionally, the argument \texttt{"}expanded\texttt{"} is a logical input that allows the user to choose between a simple return of datetimes/qualifier/values (expanded=FALSE), or a more complete and verbose output (expanded=TRUE). Expanded = TRUE includes such columns as remark codes, value qualifying text, and detection level for each parameter code. There also includes an argument \texttt{"}reshape\texttt{"}, that converts the expanded dataset to a \texttt{"}wide\texttt{"} format (each requested parameter code gets individual columns). The defaults are expanded=TRUE, and reshape=FALSE. 

<<label=getQW, echo=TRUE, eval=FALSE>>=
 
# Dissolved Nitrate parameter codes:
parameterCd <- c("00618","71851")
startDate <- "1985-10-01"
endDate <- "2012-09-30"

dfLong <- readNWISqw(siteNumber, parameterCd, 
      startDate, endDate)

# Or the wide return:
# dfWide <- readNWISqw(siteNumber, parameterCd, 
#       startDate, endDate, reshape=TRUE)

@

Site information and measured parameter information is attached to the data frame as attributes. This is discused further in section \ref{sec:metadata}. Additional metadata, such as information about the column names can be found by using the \texttt{comment} function, also described in section \ref{sec:metadata}.

<<qwmeta, echo=TRUE, eval=FALSE>>=

comment(dfLong)

@

\FloatBarrier

%------------------------------------------------------------
\subsection{Groundwater Level Data}
\label{sec:gwl}
%------------------------------------------------------------
Groundwater level measurements can be obtained with the \texttt{readNWISgwl} function. Information on the returned data can be found with the \texttt{comment} function, and attached attributes as described in section \ref{sec:metadata}.

<<gwlexample, echo=TRUE, eval=FALSE>>=
siteNumber <- "434400121275801"
groundWater <- readNWISgwl(siteNumber)
@

%------------------------------------------------------------
\subsection{Peak Flow Data}
\label{sec:peak}
%------------------------------------------------------------

Peak flow data are instantaneous discharge or stage data that record the maximum values of these variables during a flood event.  They include the annual peak flood event but can also include records of other peaks that are lower than the annual maximum. Peak discharge measurements can be obtained with the \texttt{readNWISpeak} function. Information on the returned data can be found with the \texttt{comment} function and attached attributes as described in section \ref{sec:metadata}.

<<peakexample, echo=TRUE, eval=FALSE>>=
siteNumber <- '01594440'
peakData <- readNWISpeak(siteNumber)

@


%------------------------------------------------------------
\subsection{Rating Curve Data}
\label{sec:rating}
%------------------------------------------------------------
Rating curves are the calibration curves that are used to convert measurements of stage to discharge.  Because of changing hydrologic conditions these rating curves change over time. Information on the returned data can be found with the \texttt{comment} function and attached attributes as described in section \ref{sec:metadata}.

Rating curves can be obtained with the \texttt{readNWISrating} function.

<<ratingexample, echo=TRUE, eval=FALSE>>=
ratingData <- readNWISrating(siteNumber, "base")
attr(ratingData, "RATING")

@



%------------------------------------------------------------
\subsection{Surface-Water Measurement Data}
\label{sec:meas}
%------------------------------------------------------------
These data are the discrete measurements of discharge that are made for the purpose of developing or revising the rating curve.  Information on the returned data can be found with the \texttt{comment} function and attached attributes as described in section \ref{sec:metadata}.

Surface-water measurement data can be obtained with the \texttt{readNWISmeas} function.

<<surfexample, echo=TRUE, eval=FALSE>>=
surfaceData <- readNWISmeas(siteNumber)

@


%------------------------------------------------------------
\section{Water Quality Portal Web Retrievals}
\label{sec:usgsSTORET}
%------------------------------------------------------------
There are additional water quality data sets available from the Water Quality Data Portal (\url{http://www.waterqualitydata.us/}).  These data sets can be housed in either the STORET database (data from EPA), NWIS database (data from USGS), STEWARDS database (data from USDA), and additional databases are slated to be included in the future.  Because only USGS uses parameter codes, a \texttt{"}characteristic name\texttt{"} must be supplied.  The \texttt{readWQPqw} function can take either a USGS parameter code, or a more general characteristic name in the parameterCd input argument. The Water Quality Data Portal includes data discovery tools and information on characteristic names. The following example retrieves specific conductance from a DNR site in Wisconsin. 


<<label=getQWData, echo=TRUE, eval=FALSE>>=
specificCond <- readWQPqw('WIDNR_WQX-10032762',
                'Specific conductance','2011-05-01','2011-09-30')
@

A tool for finding NWIS characteristic names can be found at: 

\url{http://www.waterqualitydata.us/public_srsnames.jsp}

\FloatBarrier

%------------------------------------------------------------
\section{Generalized Retrievals}
\label{sec:general}
%------------------------------------------------------------
The previous examples all took specific input arguments: siteNumber, parameterCd (or characteristic name), startDate, endDate, etc. However, the Web services that supply the data can accept a wide variety of additional arguments. 

%------------------------------------------------------------
\subsubsection{NWIS Sites}
\label{sec:NWISGenSite}
%------------------------------------------------------------
The function \texttt{whatNWISsites} can be used to discover NWIS sites based on any query that the NWIS Site Service offers. This is done by using the \texttt{"..."} argument, which allows the user to use any arbitrary input argument. We can then use the service here:

\url{http://waterservices.usgs.gov/rest/Site-Test-Tool.html}

to discover many options for searching for NWIS sites. For example, you may want to search for sites in a lat/lon bounding box, or only sites tidal streams, or sites with water quality samples, sites above a certain altitude, etc. The results of this site query generate a URL. For example, the tool provided a search within a specified bounding box, for sites that have daily discharge (parameter code = 00060) and temperature (parameter code = 00010). The generated URL is:

\url{http://waterservices.usgs.gov/nwis/site/?format=rdb&bBox=-83.0,36.5,-81.0,38.5&parameterCd=00010,00060&hasDataTypeCd=dv}

The following dataRetrieval code can be used to get those sites:

<<siteSearch, eval=FALSE>>=
sites <- whatNWISsites(bBox=c(-83.0,36.5,-81.0,38.5), 
                      parameterCd=c("00010","00060"),
                      hasDataTypeCd="dv")
@


%------------------------------------------------------------
\subsubsection{NWIS Data}
\label{sec:NWISGenData}
%------------------------------------------------------------
For NWIS data, the function \texttt{readNWISdata} can be used. The argument listed in the R help file is \texttt{"..."} and \texttt{"}service\texttt{"} (only for data requests). Table \ref{tab:NWISGeneral} describes the services are available.

\begin{table}[!ht]
\begin{minipage}{\linewidth}
{\footnotesize
\caption{NWIS general data calls} 
\label{tab:NWISGeneral}
\begin{tabular}{lll}
  \hline
\multicolumn{1}{c}{\textbf{\textsf{Service}}} &
\multicolumn{1}{c}{\textbf{\textsf{Description}}}  &
\multicolumn{1}{c}{\textbf{\textsf{Reference URL}}} \\  [0pt]
  \hline
  daily values &  dv & \url{http://waterservices.usgs.gov/rest/DV-Test-Tool.html}\\
  [5pt]instantaneous & iv & \url{http://waterservices.usgs.gov/rest/IV-Test-Tool.html}\\
  [5pt]groundwater levels & gwlevels & \url{http://waterservices.usgs.gov/rest/GW-Levels-Test-Tool.html}\\
  [5pt]water quality & qwdata & \url{http://nwis.waterdata.usgs.gov/nwis/qwdata}\\
   \hline
\end{tabular}
}
\end{minipage}
\end{table}

The \texttt{"..."} argument allows the user to create their own queries based on the instructions found in the web links above. The links provide instructions on how to create a URL to request data. Perhaps you want sites only in Wisconsin, with a drainage area less than 50 mi$^2$, and the most recent daily dischage data. That request would be done as follows:

<<dataExample>>=
dischargeWI <- readNWISdata(service="dv",
                           stateCd="WI",
                           parameterCd="00060",
                           drainAreaMin="50",
                           statCd="00003")
names(dischargeWI)
nrow(dischargeWI)

siteInfo <- attr(dischargeWI, "siteInfo")
head(siteInfo)

@

%------------------------------------------------------------
\subsubsection{WQP Sites}
\label{sec:WQPGenSite}
%------------------------------------------------------------

Just as with NWIS, the Water Quality Portal (WQP) offers a variety of ways to search for sites and request data. The possible Web service arguments for WQP site searches is found here:

\url{http://www.waterqualitydata.us/webservices_documentation.jsp}

To discover available sites in the WQP in New Jersey that have measured Chloride, use the function \texttt{whatWQPsites}.

<<NJChloride, eval=FALSE>>=

sitesNJ <- whatWQPsites(statecode="US:34",
                       characteristicName="Chloride")

@


%------------------------------------------------------------
\subsubsection{WQP Data}
\label{sec:WQPGenData}
%------------------------------------------------------------
Finally, to get data from the WQP using generalized Web service calls, use the function \texttt{readWQPdata}. For example, to get all the pH data in Wisconsin:

<<phData, eval=FALSE>>=

dataPH <- readWQPdata(statecode="US:55", 
                 characteristicName="pH")

@



\FloatBarrier

\clearpage

%------------------------------------------------------------
\section{Embedded Metadata}
\label{sec:metadata}
%------------------------------------------------------------
All data frames returned from the Web services have some form of associated metadata. This information is included as attributes to the data frame. All data frames will have a \texttt{url} (returning a character of the url used to obtain the data), \texttt{siteInfo} (returning a data frame with information on sites),  and \texttt{queryTime} (returning a POSIXct datetime) attributes. For example, the url and query time used to obtain the data can be found as follows:

<<meta1, eval=TRUE>>=

attr(dischargeWI, "url")

attr(dischargeWI, "queryTime")

siteInfo <- attr(dischargeWI, "siteInfo")

@

Depending on the format that the data was obtained (RDB, WaterML1, etc), there will be additional information embedded in the data frame as attributes. To discover the available attributes:

<<meta2, eval=TRUE>>=

names(attributes(dischargeWI))

@

For data obtained from \texttt{readNWISuv}, \texttt{readNWISdv}, \texttt{readNWISgwl} there are two attributes that are particularly useful: \texttt{siteInfo} and \texttt{variableInfo}.

<<meta3, eval=TRUE>>=

siteInfo <- attr(dischargeWI, "siteInfo")
head(siteInfo)

variableInfo <- attr(dischargeWI, "variableInfo")


@

Data obtained from \texttt{readNWISpeak}, \texttt{readNWISmeas}, and \texttt{readNWISrating}, the \texttt{comment} attribute is useful.

<<meta5, eval=FALSE>>=
comment(peakData)

#Which is equivalent to:
# attr(peakData, "comment")
@



%------------------------------------------------------------ 
\section{Getting Started in R}
\label{sec:appendix1}
%------------------------------------------------------------ 
This section describes the options for downloading and installing the dataRetrieval package.

%------------------------------------------------------------
\subsection{New to R?}
%------------------------------------------------------------ 
If you are new to R, you will need to first install the latest version of R, which can be found here: \url{http://www.r-project.org/}.

At any time, you can get information about any function in R by typing a question mark before the functions name.  This will open a file (in RStudio, in the Help window) that describes the function, the required arguments, and provides working examples. This will open a help file similar to Figure \ref{fig:help}. To see the raw code for a particular code, type the name of the function, without parentheses.


<<helpFunc,eval = FALSE>>=
?readNWISpCode
@

\FloatBarrier


\begin{figure}[ht!]
\centering
 \resizebox{0.95\textwidth}{!}{\includegraphics{Rhelp.png}} 
\caption{A simple R help file}
\label{fig:help}
\end{figure}

Additionally, many R packages have vignette files attached (such as this paper). To view the vignette:
<<seeVignette,eval = FALSE>>=
vignette(dataRetrieval)
@

\FloatBarrier
\clearpage
%------------------------------------------------------------
\subsection{R User: Installing dataRetrieval}
%------------------------------------------------------------ 
The following command installs dataRetrieval and subsequent required packages:

<<installFromCran,eval = FALSE>>=
install.packages("dataRetrieval")
@

After installing the package, you need to open the library each time you re-start R.  This is done with the simple command:
<<openLibraryTest, eval=FALSE>>=
library(dataRetrieval)
@


%------------------------------------------------------------ 
\section{Creating Tables in Microsoft\textregistered\ Software from R}
\label{app:createWordTable}
%------------------------------------------------------------
There are a few steps that are required in order to create a table in Microsoft\textregistered\ software (Excel, Word, PowerPoint, etc.) from an R data frame. There are certainly a variety of good methods, one of which is detailed here. The example we will step through here will be to create a table in Microsoft Excel based on the data frame tableData:

<<label=getSiteApp, echo=TRUE, eval=FALSE>>=
availableData <- whatNWISdata(siteNumber, "dv")
dailyData <- availableData["00003" == availableData$stat_cd,]

tableData <- with(dailyData, 
      data.frame(
        shortName=srsname, 
        Start=begin_date, 
        End=end_date, 
        Count=count_nu,
        Units=parameter_units)
      )
@

First, save the data frame as a tab delimited file (you don't want to use comma delimited because there are commas in some of the data elements):


<<label=saveData, echo=TRUE, eval=FALSE>>=
write.table(tableData, file="tableData.tsv",sep="\t",
            row.names = FALSE,quote=FALSE)
@

This will save a file in your working directory called tableData.tsv.  You can see your working directory by typing getwd() in the R console. Opening the file in a general-purpose text editor, you should see the following:

\begin{verbatim}
shortName  Start  End	Count	Units
Temperature, water	2010-10-01	2012-06-24	575	deg C
Stream flow, mean. daily	1948-01-01	2013-03-13	23814	ft3/s
Specific conductance	2010-10-01	2012-06-24	551	uS/cm @25C
Suspended sediment concentration (SSC)	1980-10-01	1991-09-30	3651	mg/l
Suspended sediment discharge	1980-10-01	1991-09-30	3652	tons/day
\end{verbatim}

Next, follow the steps below to open this file in Excel:
\begin{enumerate}
\item Open Excel
\item Click on the File tab
\item Click on the Open option
\item Navigate to the working directory (as shown in the results of \texttt{getwd()})
\item Next to the File name text box, change the dropdown type to All Files (*.*)
\item Double click tableData.tsv
\item A text import wizard will open up, in the first window, choose the Delimited radio button if it is not automatically picked, then click on Next.
\item In the second window, click on the Tab delimiter if it is not automatically checked, then click Finished.
\item Use the many formatting tools within Excel to customize the table
\end{enumerate}

From Excel, it is simple to copy and paste the tables in other Microsoft\textregistered\ software. An example using one of the default Excel table formats is here. Additional formatting could be requried in Excel, for example converting u to  $\mu$.

\begin{figure}[ht!]
\centering
 \resizebox{0.9\textwidth}{!}{\includegraphics{table1.png}} 
\caption{A simple table produced in Microsoft\textregistered\ Excel.}
\label{overflow}
\end{figure}

\clearpage

%-------------------------------------
\section{Disclaimer}
%------------------------------------
This information is preliminary and is subject to revision. It is being provided to meet the need for timely best science. The information is provided on the condition that neither the U.S. Geological Survey nor the U.S. Government may be held liable for any damages resulting from the authorized or unauthorized use of the information.


\end{document}
